# src/lib/text.py
from __future__ import annotations

import re
import unicodedata
from collections import Counter
from typing import Dict, List, Tuple

wordRe = re.compile(r"\b\w+(?:-\w+)*\b", re.UNICODE) # \w –∏ –¥–µ—Ñ–∏—Å—ã

spaceRe = re.compile(r"\s+") #—Å–ª–∏–≤–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –º –≤ –æ–¥–∏–Ω


def specials2Space(text: str) -> str:
    '–∑–∞–º–µ–Ω—è–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –Ω–∞ –ø—Ä–æ–±–µ–ª'
    chars = []
    append = chars.append
    for ch in text:
        cat = unicodedata.category(ch)
        if cat in {"Cc", "Cf"}:
            append(" ")
        else:
            append(ch)
    return "".join(chars)


def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:

    if yo2e:
        text = text.replace("—ë", "–µ").replace("–Å", "–ï")

    text = specials2Space(text)
    text = spaceRe.sub(" ", text).strip()

    if casefold:
        text = text.casefold()

    return text


def tokenize(text: str) -> List[str]:
    return wordRe.findall(text)


def count_freq(tokens: List[str]) -> Dict[str, int]:
    '—Å—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—ã'
    return dict(Counter(tokens))


def top_n(freq: Dict[str, int], n: int = 5) -> List[Tuple[str, int]]:
    '–≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã –∏–ª–∏ –∞–ª—Ñ–∞–≤–∏—Ç—É'
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º: —Å–Ω–∞—á–∞–ª–∞ –ø–æ -count, –∑–∞—Ç–µ–º –ø–æ —Å–ª–æ–≤—É
    items = sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))
    return items[:n]

# #normalize
# print(normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t"))
# print(normalize("—ë–∂–∏–∫, –Å–ª–∫–∞"))
# print(normalize("Hello\r\nWorld"))
# print(normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "))
# print()
#
# #tokenize (normalized)
# print(tokenize(normalize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä")))
# print(tokenize(normalize("hello.txt,world!!!")))
# print(tokenize(normalize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ")))
# print(tokenize(normalize("2025 –≥–æ–¥")))
# print(tokenize(normalize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ")))
# print()
#
# #count_freq + top_n
# tokens1 = ["a", "b", "a", "c", "b", "a"]
# freq1 = count_freq(tokens1)
# print(freq1)
# print(top_n(freq1, n=2))
#
# tokens2 = ["bb", "aa", "bb", "aa", "cc"]
# freq2 = count_freq(tokens2)
# print(freq2)
# print(top_n(freq2, n=2))